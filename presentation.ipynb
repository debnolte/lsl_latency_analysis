{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# LSL hands-on:\n",
    "# What did we learn comparing EEG and Unity data streams?\n",
    "<br>\n",
    "\n",
    "### Tea Time 12.03.2020 -  Marc Vidal De Palol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "1. Why aligning data streams is important?\n",
    "2. Delay, jitter and latency\n",
    "3. What is LSL (lab streaming layer)?\n",
    "4. Designing the test\n",
    "5. How did we analyze the data?\n",
    "6. Results\n",
    "7. Conclusions and remarks\n",
    "8. Future outlook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Why aligning data streams is important?\n",
    "\n",
    "Data streaming devices have different:\n",
    "- Sampling rates \n",
    "- CPU clocks\n",
    "\n",
    "\n",
    "<img src=\"img/sines.png\" width=\"40%\"><img src=\"img/cpu.png\" width=\"20%\">\n",
    "<br>\n",
    "\n",
    "They can also be connected via network (LAN or WLAN) -> delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Why aligning data streams is important?\n",
    "\n",
    "Example:\n",
    "\n",
    "<img src=\"img/westdrive.png\" width=\"70%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Why aligning data streams is important?\n",
    "\n",
    "Example:<br>\n",
    "\n",
    "- Westdrive (Unity): 60 FPS <br>\n",
    "<img src=\"img/westdrive.png\" width=\"30%\">\n",
    "- Toby eye tracker: 90 Hz <br>\n",
    "<img src=\"img/hmd.png\" width=\"20%\">\n",
    "- TMSI Rega EEG amplifier: 1024 Hz <br>\n",
    "<img src=\"img/ant_cap.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Delay, latency and jitter\n",
    "\n",
    "<img alt=\"ping\" src=\"img/delay.gif\" width=\"40%\">\n",
    "\n",
    "<br>\n",
    "\n",
    "Differences:\n",
    "- Delay: time for some data to move from one endpoint to another\n",
    "- Latency: one-way delay\n",
    "- Jitter: delay inconsistency between each packet\n",
    "\n",
    "Delay contributors:\n",
    "- Processing: package analysis time\n",
    "- Queueing: time between being queued and sent\n",
    "- Transmission: time to push the data into the wire\n",
    "- Propagation: time influenced by the distance\n",
    "\n",
    "Source: https://www.callstats.io/blog/2018/03/07/difference-between-jitter-and-latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. What is LSL (lab streaming layer)?\n",
    "\n",
    "Two ways of solving the alignment of time series data:\n",
    "- manually-> more time consuming, but more control\n",
    "- automatically via soft solution (e.g. LSL) -> less time consuming, less control\n",
    "\n",
    "Also advantages of LSL:\n",
    "- open source\n",
    "- cross platform (Win, Linux, MacOS, Android, iOS)\n",
    "- multi API language interfaces (C, C++, Python, Java, C#, MATLAB)\n",
    "- many tools around it\n",
    "- scientific community support\n",
    "- XDF stored data\n",
    "\n",
    "Source: https://labstreaminglayer.readthedocs.io/info/intro.html#what-is-lsl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. What is LSL (lab streaming layer)?\n",
    "\n",
    "How to use LSL? Requirements:\n",
    "- LabRecorder app\n",
    "- liblsl library with code defining your data streams\n",
    "\n",
    "    and/or\n",
    "\n",
    "- LSL community app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3. What is LSL (lab streaming layer)?\n",
    "\n",
    "The Lab Recorder (with BIDS support):\n",
    "\n",
    "\n",
    "<img src=\"img/labrecorder.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. What is LSL (lab streaming layer)?\n",
    "\n",
    "Code example in C# defining a data stream:\n",
    "```csharp\n",
    "using LSL;\n",
    "\n",
    "public class yourClass\n",
    "{\n",
    "    private liblsl.StreamInfo lslStreamInfo;\n",
    "    private liblsl.StreamOutlet lslOutlet;\n",
    "\n",
    "    void startingMethod() { // normally Start() in Unity\n",
    "        lslStreamInfo = new liblsl.StreamInfo(\n",
    "            sName,\n",
    "            sType,\n",
    "            nValues,\n",
    "            nominalRate,\n",
    "            LslChannelFormat,\n",
    "            uuid);\n",
    "        lslOutlet = new liblsl.StreamOutlet(streamInfo);\n",
    "    }\n",
    "\n",
    "    void sendingMethod() { // normally FixedUpdate() in Unity\n",
    "        var data = new float[size];\n",
    "        lslOutlet.push_sample(data);\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Designing the test\n",
    "\n",
    "Situation: Every 500ms a beep sound is played and the background color changes one frame from black to white.\n",
    "\n",
    "Unity (90 FPS):\n",
    "- color change (black or white background)\n",
    "- 100 ms beep sound (audio playing or not)\n",
    "\n",
    "EEG (1024 Hz):\n",
    "- photodiode (light sensor)\n",
    "- microphone (audio sensor)\n",
    "\n",
    "Recording setups with different:\n",
    "- HMDs (Head-mounted display)\n",
    "- computers (single and two LAN-connected)\n",
    "- Unity builds\n",
    "- long and short recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. Designing the test\n",
    "\n",
    "<img src=\"img/test_design.png\" width=\"85%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. Designing the test\n",
    "Background result:\n",
    "\n",
    "\n",
    "<img src=\"img/background.gif\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. Designing the test\n",
    "Extra:\n",
    "\n",
    "<img src=\"img/editor.png\" width=\"35%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. How did we analyze the data?\n",
    "<img src=\"img/plot0.png\" width=\"85%\">\n",
    "\n",
    "1. Read the XDF files and select the right data\n",
    "    - Unity timestamps\n",
    "    - Black/White and notPlaying/isPlaying\n",
    "    - EEG timestamps\n",
    "    - Photodiode and microphone values\n",
    "2. Recalculated the timestamps from 0\n",
    "3. Visualized the data\n",
    "4. Timestamps comparison (length, duration, sample count...): file info vs original vs calculated\n",
    "5. Descriptive statistics of timestamps distributions\n",
    "6. Peak detections and latency calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7. Conclusions and remarks\n",
    "\n",
    "<img src=\"img/unity_before.png\" width=\"55%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 8. Future outlook\n",
    "\n",
    "1. New recordings and data analysis using a \"heavy\" Unity project\n",
    "2. Figure out about the non-matching numbers on the file info (sample count, first timestamp, etc.)\n",
    "3. Check if Unity timestamps received before the EEG ones are a mistake. If not, why?\n",
    "4. Clean the repos we created and commented the code for further use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "- [Liblsl](https://github.com/sccn/liblsl/releases)\n",
    "- [LabRecorder](https://github.com/labstreaminglayer/App-LabRecorder/releases)\n",
    "- [LSL4Unity](https://github.com/labstreaminglayer/LSL4Unity)\n",
    "- [LSL Apps](https://github.com/sccn/labstreaminglayer/tree/master/Apps)\n",
    "- [LSL documentation reference](https://labstreaminglayer.readthedocs.io/)\n",
    "- [LSL latency analysis](https://github.com/mvidaldp/lsl_latency_analysis)\n",
    "- [Unity latency project](https://github.com/mvidaldp/black_n_white)\n",
    "- [Audio tones generator](https://github.com/mvidaldp/pytonegen)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
